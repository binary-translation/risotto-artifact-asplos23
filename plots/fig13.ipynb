{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d65ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = \"../results/openssl.csv\"\n",
    "input_sqlite_csv = \"../results/sqlite.csv\"\n",
    "output_pdf = \"../results/fig13.pdf\"\n",
    "baseline = \"x86_64,qemu,qemu\"\n",
    "base_arch, base_runtime, base_tag = baseline.split(',')\n",
    "df = pd.read_csv(input_csv, sep=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd6dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which ciphers to plot\n",
    "ciphers = [ #'openssl.md5-64', 'openssl.md5-256',\n",
    "            'openssl.md5-1024', 'openssl.md5-8192',\n",
    "            #'openssl.rsa512-sign', 'openssl.rsa512-verify',\n",
    "            'openssl.rsa1024-sign', 'openssl.rsa1024-verify',\n",
    "            'openssl.rsa2048-sign', 'openssl.rsa2048-verify',\n",
    "            #'openssl.sha1-64', 'openssl.sha1-256',\n",
    "            'openssl.sha1-1024', 'openssl.sha1-8192',\n",
    "            #'openssl.sha256-64', 'openssl.sha256-256',\n",
    "            'openssl.sha256-1024', 'openssl.sha256-8192'\n",
    "          ]\n",
    "\n",
    "df = df.loc[df['bench'].isin(ciphers)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c28a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the sqlite results\n",
    "df_sqlite = pd.read_csv(input_sqlite_csv, sep=';')\n",
    "df_sqlite = df_sqlite.loc[df_sqlite['bench'] == \"micro.sqlite-total-multi\"]\n",
    "df_sqlite['bench'] = \"xxxxxxx.sqlite\"\n",
    "# convert to ops/s\n",
    "df_sqlite['value'] = 269236 / (df_sqlite['value'] / 1000)\n",
    "df_sqlite['unit'] = \"ops/s\"\n",
    "\n",
    "df_sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5157dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ df, df_sqlite] , ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = df.loc[df['tag'] == 'qemu']\n",
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean for each baseline benchmark\n",
    "base_means = {}\n",
    "for b in set(base_df['bench']):\n",
    "    base_means[b] = np.array(base_df.loc[base_df['bench'] == b]['value'].values, dtype=np.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e11e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean of every benchmark for each runtime\n",
    "mean_df = pd.DataFrame()\n",
    "for b in sorted(set(df['bench'])):\n",
    "    df_b = df.loc[df['bench'] == b]\n",
    "    tmp_dict = { 'bench': b }\n",
    "    for t in set(df_b['tag']):\n",
    "        df_b_t = df_b.loc[df_b['tag'] == t]\n",
    "        tmp_dict[t] = np.mean(df_b_t['value'])\n",
    "    mean_df = mean_df.append(tmp_dict, ignore_index=True)\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ec17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all results from original df to these means\n",
    "df_norm = pd.DataFrame(columns=['arch', 'bench', 'dataset', 'threads', 'unit', 'value', 'runtime',\n",
    "                                'tag', 'norm', 'label'])\n",
    "norm_vals = []\n",
    "for row in df.itertuples():\n",
    "    try:\n",
    "        if row.arch == base_arch and row.runtime == base_runtime and row.tag == base_tag:\n",
    "            continue\n",
    "        #if row.bench == \"sqlite.speedtest1\":\n",
    "         #   norm = base_means[row.bench] / float(row.value)      # speedup\n",
    "        #else:\n",
    "        norm = float(row.value) / base_means[row.bench]    # relative perf\n",
    "        \n",
    "        # norm = 100 * (base_means[row.bench] - float(row.value)) / base_means[row.bench]\n",
    "        dct = row._asdict()\n",
    "        dct['norm'] = norm\n",
    "        dct['label'] = f\"{dct['tag']}\"\n",
    "        # dct['label'] = f\"{dct['runtime']}-{dct['tag']}\"\n",
    "        del dct['Index']\n",
    "        del dct['cmdline']\n",
    "        norm_vals.append(dct)\n",
    "    except KeyError:\n",
    "        pass\n",
    "df_norm = df_norm.append(norm_vals, ignore_index=True)\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4172c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def sorted_nicely( l ): \n",
    "    \"\"\" Sort the given iterable in the way that humans expect.\"\"\" \n",
    "    convert = lambda text: int(text) if text.isdigit() else text \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(l, key = alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ce109",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,2.5), dpi=500)\n",
    "sbs.set(style=\"whitegrid\")\n",
    "palette = {\n",
    "    'orange': '#faa200',\n",
    "    'sky blue': '#00b7ec',\n",
    "    'bluish green': '#00a077',\n",
    "    'yellow': '#f5e636',\n",
    "    'blue': '#0077b8',\n",
    "    'vermillion': '#f3640d',\n",
    "    'reddish purple': '#e47ead'\n",
    "}\n",
    "ax = sbs.barplot(data=df_norm, x='bench', y='norm', hue='label',\n",
    "                 hue_order=['risotto', 'native'], order=sorted_nicely(base_means))\n",
    "plt.grid(visible=True, axis='y')\n",
    "plt.xticks(ticks=range(0, len(set(df_norm['bench']))),\n",
    "           labels=[ l[8:] for l in sorted_nicely(base_means) ],  # remove openssl. from the x ticks\n",
    "           rotation=45, ha=\"right\", fontsize='xx-small')\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Speedup w.r.t. QEMU\")\n",
    "plt.ylim((0, 27))\n",
    "plt.axhline(y=1, xmin=0, xmax=1, color='tomato', linewidth=2.5)\n",
    "# Annotate the raw value of the baseline\n",
    "for idx, value in enumerate(sorted_nicely(set(base_means))):\n",
    "    if base_means[value] > 1000000:\n",
    "        v = f\"{base_means[value] / 1000000:.0f}M\"\n",
    "    elif base_means[value] > 1000:\n",
    "        v = f\"{base_means[value] / 1000:.0f}k\"\n",
    "    else:\n",
    "        v = f\"{base_means[value]:.0f}\"\n",
    "    tmp = max(mean_df.loc[mean_df['bench'] == value].values[0][1:]) / base_means[value]\n",
    "    plt.text(idx, tmp+1, f\"{v}\", fontsize='xx-small', color='tomato', rotation=90, ha='center')\n",
    "    #plt.text(idx, max(tmp+.3, 21), f\"{v}\", fontsize='xx-small', color='tomato', rotation=45, ha='center')\n",
    "#plt.vlines(range(0, len(set(base_means))), ymin=0, ymax=20.8, linestyle='dashed', colors='grey', linewidth=.5, zorder=0)\n",
    "\n",
    "# Set color + hatch\n",
    "style = {\n",
    "    'fill': [ True, True ],\n",
    "    'color': [ palette['bluish green'], palette['orange'] ],\n",
    "    'hatch': [ '', '', ''],\n",
    "    'edgecolor': [ 'black', 'black', 'black' ]\n",
    "}\n",
    "for idx, bar in enumerate(ax.patches):\n",
    "    bar_nr = int(idx / int(len(base_means)))\n",
    "    bar.set(color=style['color'][bar_nr], fill=style['fill'][bar_nr],\n",
    "            hatch=style['hatch'][bar_nr], edgecolor=style['edgecolor'][bar_nr])\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(.5, 1.15), borderaxespad=0, ncol=2, fontsize='x-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b6f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fig13.pdf, dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06ee3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted_nicely(base_means):\n",
    "    print(f\"{i:25}: {base_means[i]:>20.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(value)\n",
    "max(mean_df.loc[mean_df['bench'] == value].values[0][1:]) / base_means[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5effd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df['risotto-speedup'] = mean_df['risotto'] / mean_df['qemu']\n",
    "mean_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
